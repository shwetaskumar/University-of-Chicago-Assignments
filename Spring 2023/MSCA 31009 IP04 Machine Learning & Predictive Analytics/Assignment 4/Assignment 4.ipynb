{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Import the data: You are provided separate .csv files for train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (507, 148)\n",
      "Test Data: (168, 148)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "print(\"Train Data: \" + str(train_data.shape) + \"\\nTest Data: \" + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Remove any rows that have missing data across both sets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (507, 148)\n",
      "Test Data: (168, 148)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "print(\"Train Data: \" + str(train_data.shape) + \"\\nTest Data: \" + str(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) The target variable (dependent variable) is called \"class\", make sure to separate this out into a \"y_train\" and \"y_test\" and remove from your \"X_train\" and \"X_test\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['class'], axis=1)\n",
    "X_test = test_data.drop(['class'], axis=1)\n",
    "y_train = train_data['class']\n",
    "y_test = test_data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Scale all features / predictors (NOT THE TARGET VARIABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest Classifier - Base Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by creating a simple Random Forest only using default parameters - this will let us compare SVMs to Random Forest in multiclass problems.<br>\n",
    "a) Use the RandomForestClassifier in sklearn. Fit your model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use the fitted model to predict on test data. Use the .predict() method to get the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['building ', 'concrete ', 'building ', 'concrete ', 'concrete ',\n",
       "       'grass ', 'car ', 'car ', 'building ', 'tree ', 'building ',\n",
       "       'asphalt ', 'building ', 'grass ', 'shadow ', 'building ', 'tree ',\n",
       "       'soil ', 'building ', 'shadow ', 'pool ', 'shadow ', 'concrete ',\n",
       "       'tree ', 'grass ', 'concrete ', 'grass ', 'building ', 'building ',\n",
       "       'building ', 'asphalt ', 'shadow ', 'concrete ', 'tree ', 'tree ',\n",
       "       'concrete ', 'asphalt ', 'concrete ', 'tree ', 'concrete ',\n",
       "       'concrete ', 'tree ', 'building ', 'building ', 'building ',\n",
       "       'grass ', 'grass ', 'shadow ', 'concrete ', 'soil ', 'shadow ',\n",
       "       'tree ', 'car ', 'car ', 'asphalt ', 'pool ', 'building ', 'tree ',\n",
       "       'grass ', 'grass ', 'car ', 'car ', 'pool ', 'building ', 'soil ',\n",
       "       'grass ', 'building ', 'building ', 'building ', 'soil ',\n",
       "       'concrete ', 'building ', 'asphalt ', 'pool ', 'pool ', 'shadow ',\n",
       "       'building ', 'grass ', 'asphalt ', 'asphalt ', 'pool ', 'pool ',\n",
       "       'building ', 'concrete ', 'building ', 'shadow ', 'concrete ',\n",
       "       'grass ', 'asphalt ', 'grass ', 'grass ', 'grass ', 'concrete ',\n",
       "       'concrete ', 'concrete ', 'grass ', 'pool ', 'car ', 'shadow ',\n",
       "       'tree ', 'grass ', 'asphalt ', 'tree ', 'car ', 'tree ',\n",
       "       'asphalt ', 'grass ', 'building ', 'concrete ', 'grass ',\n",
       "       'asphalt ', 'grass ', 'grass ', 'car ', 'concrete ', 'tree ',\n",
       "       'grass ', 'concrete ', 'concrete ', 'car ', 'car ', 'grass ',\n",
       "       'shadow ', 'pool ', 'tree ', 'asphalt ', 'tree ', 'pool ',\n",
       "       'building ', 'grass ', 'soil ', 'asphalt ', 'asphalt ',\n",
       "       'concrete ', 'asphalt ', 'grass ', 'shadow ', 'pool ', 'pool ',\n",
       "       'pool ', 'car ', 'grass ', 'concrete ', 'asphalt ', 'concrete ',\n",
       "       'asphalt ', 'building ', 'shadow ', 'shadow ', 'tree ', 'grass ',\n",
       "       'asphalt ', 'tree ', 'shadow ', 'concrete ', 'concrete ',\n",
       "       'concrete ', 'tree ', 'asphalt ', 'concrete ', 'grass ', 'tree ',\n",
       "       'tree ', 'car ', 'soil ', 'grass ', 'grass ', 'concrete '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Calculate the confusion matrix and classification report for the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1, 19,  0,  4,  1,  0,  0,  0,  0],\n",
       "       [ 1,  2, 12,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  3,  0, 19,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0, 24,  0,  0,  0,  5],\n",
       "       [ 1,  0,  1,  0,  0, 13,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0, 14,  0,  0],\n",
       "       [ 0,  1,  0,  5,  3,  0,  0,  5,  0],\n",
       "       [ 0,  0,  0,  1,  1,  0,  0,  0, 15]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.74      1.00      0.85        14\n",
      "   building        0.76      0.76      0.76        25\n",
      "        car        0.92      0.80      0.86        15\n",
      "   concrete        0.66      0.83      0.73        23\n",
      "      grass        0.83      0.83      0.83        29\n",
      "       pool        1.00      0.87      0.93        15\n",
      "     shadow        1.00      0.88      0.93        16\n",
      "       soil        0.83      0.36      0.50        14\n",
      "       tree        0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.80       168\n",
      "   macro avg       0.83      0.80      0.80       168\n",
      "weighted avg       0.82      0.80      0.80       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d)  Calculate predictions for the training data & build the classification report & confusion matrix. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 97,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 21,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 93,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 83,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 14,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 45,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 20,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 89]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = clf.predict(X_train_scaled)\n",
    "confusion_matrix(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      1.00      1.00        45\n",
      "   building        1.00      1.00      1.00        97\n",
      "        car        1.00      1.00      1.00        21\n",
      "   concrete        1.00      1.00      1.00        93\n",
      "      grass        1.00      1.00      1.00        83\n",
      "       pool        1.00      1.00      1.00        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      1.00      1.00        20\n",
      "       tree        1.00      1.00      1.00        89\n",
      "\n",
      "    accuracy                           1.00       507\n",
      "   macro avg       1.00      1.00      1.00       507\n",
      "weighted avg       1.00      1.00      1.00       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are signs of overfitting as it can be seen that the precision, recall and f1-scores are 1 for all labels on the train dataset and not on the test data. The model is performing very well on trained data but not on unseen/test data for most of the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Identify the top 5 features. Feel free to print a list OR to make a plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_features = X_train.columns[indices][:5]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title(\"Top 5 Important Features\")\n",
    "bar_plot = plt.bar(range(len(top_features)), importances[indices][:5], align='center')\n",
    "plt.xticks(range(len(top_features)), top_features)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "for i, v in enumerate(importances[indices][:5]):\n",
    "    plt.text(i, v, str(round(v,2)), ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LinearSVM Classifier - Base Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple LinearSVC Classifier only using default parameters.<br>\n",
    "a) Use the LinearSVC in sklearn. Fit your model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_svc = LinearSVC(max_iter=10000, random_state=42)\n",
    "l_svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use the fitted model to predict on test data. Use the .predict() method to get the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['car ', 'concrete ', 'building ', 'concrete ', 'asphalt ', 'tree ',\n",
       "       'car ', 'car ', 'building ', 'tree ', 'building ', 'asphalt ',\n",
       "       'building ', 'grass ', 'shadow ', 'building ', 'grass ',\n",
       "       'building ', 'building ', 'shadow ', 'pool ', 'shadow ',\n",
       "       'concrete ', 'tree ', 'grass ', 'concrete ', 'grass ', 'building ',\n",
       "       'building ', 'building ', 'asphalt ', 'shadow ', 'building ',\n",
       "       'grass ', 'tree ', 'building ', 'asphalt ', 'concrete ', 'tree ',\n",
       "       'concrete ', 'concrete ', 'tree ', 'building ', 'building ',\n",
       "       'building ', 'grass ', 'asphalt ', 'shadow ', 'building ', 'soil ',\n",
       "       'tree ', 'tree ', 'car ', 'car ', 'shadow ', 'pool ', 'building ',\n",
       "       'grass ', 'tree ', 'grass ', 'car ', 'car ', 'pool ', 'concrete ',\n",
       "       'concrete ', 'grass ', 'building ', 'building ', 'building ',\n",
       "       'soil ', 'concrete ', 'building ', 'car ', 'pool ', 'pool ',\n",
       "       'shadow ', 'building ', 'grass ', 'shadow ', 'grass ', 'pool ',\n",
       "       'pool ', 'building ', 'building ', 'concrete ', 'shadow ',\n",
       "       'building ', 'grass ', 'asphalt ', 'grass ', 'grass ', 'grass ',\n",
       "       'building ', 'concrete ', 'building ', 'grass ', 'pool ', 'tree ',\n",
       "       'shadow ', 'tree ', 'grass ', 'asphalt ', 'tree ', 'building ',\n",
       "       'tree ', 'asphalt ', 'grass ', 'building ', 'tree ', 'grass ',\n",
       "       'asphalt ', 'grass ', 'tree ', 'asphalt ', 'concrete ', 'tree ',\n",
       "       'grass ', 'concrete ', 'concrete ', 'car ', 'car ', 'tree ',\n",
       "       'shadow ', 'pool ', 'tree ', 'asphalt ', 'grass ', 'shadow ',\n",
       "       'building ', 'grass ', 'concrete ', 'asphalt ', 'asphalt ',\n",
       "       'concrete ', 'asphalt ', 'grass ', 'asphalt ', 'pool ', 'pool ',\n",
       "       'pool ', 'car ', 'grass ', 'concrete ', 'asphalt ', 'concrete ',\n",
       "       'asphalt ', 'building ', 'shadow ', 'shadow ', 'tree ',\n",
       "       'concrete ', 'car ', 'tree ', 'shadow ', 'concrete ', 'concrete ',\n",
       "       'soil ', 'tree ', 'asphalt ', 'concrete ', 'grass ', 'tree ',\n",
       "       'tree ', 'car ', 'soil ', 'grass ', 'grass ', 'concrete '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lsvc = l_svc.predict(X_test_scaled)\n",
    "y_pred_lsvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Calculate the confusion matrix and classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0, 21,  0,  2,  2,  0,  0,  0,  0],\n",
       "       [ 0,  1, 12,  1,  0,  0,  0,  0,  1],\n",
       "       [ 1,  5,  0, 16,  0,  0,  0,  0,  1],\n",
       "       [ 1,  0,  0,  1, 21,  0,  0,  0,  6],\n",
       "       [ 1,  0,  1,  0,  0, 12,  1,  0,  0],\n",
       "       [ 2,  0,  0,  0,  0,  0, 13,  0,  1],\n",
       "       [ 0,  4,  0,  3,  3,  0,  0,  4,  0],\n",
       "       [ 0,  0,  0,  1,  2,  0,  0,  0, 14]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_lsvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.72      0.93      0.81        14\n",
      "   building        0.68      0.84      0.75        25\n",
      "        car        0.92      0.80      0.86        15\n",
      "   concrete        0.67      0.70      0.68        23\n",
      "      grass        0.75      0.72      0.74        29\n",
      "       pool        1.00      0.80      0.89        15\n",
      "     shadow        0.87      0.81      0.84        16\n",
      "       soil        1.00      0.29      0.44        14\n",
      "       tree        0.61      0.82      0.70        17\n",
      "\n",
      "    accuracy                           0.75       168\n",
      "   macro avg       0.80      0.75      0.75       168\n",
      "weighted avg       0.78      0.75      0.74       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_lsvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d)  Calculate predictions for the training data & build the classification report & confusion matrix. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 97,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 21,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 93,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0, 80,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0, 14,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 45,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 20,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 89]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train_lsvc = l_svc.predict(X_train_scaled)\n",
    "confusion_matrix(y_train, y_pred_train_lsvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      1.00      1.00        45\n",
      "   building        0.99      1.00      0.99        97\n",
      "        car        1.00      1.00      1.00        21\n",
      "   concrete        1.00      1.00      1.00        93\n",
      "      grass        1.00      0.96      0.98        83\n",
      "       pool        1.00      1.00      1.00        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      1.00      1.00        20\n",
      "       tree        0.98      1.00      0.99        89\n",
      "\n",
      "    accuracy                           0.99       507\n",
      "   macro avg       1.00      1.00      1.00       507\n",
      "weighted avg       0.99      0.99      0.99       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train_lsvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are signs of overfitting as it can be seen that the precision, recall and f1-scores are 1 for majority of the labels on the train dataset and not on the test data. The model is performing very well on trained data but not on unseen/test data for most of the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Support Vector Machine Classifier + Linear Kernel + Grid Search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use GridSearchCV to try various hyperparameters in a SVM with linear kernel.<br>\n",
    "a) Use SVC from sklearn with kernel = \"linear\". Run the GridSearchCV using the following (SVMs run much faster than RandomForest):\n",
    "\n",
    "C: 0.01 - 10 in increments of 0.2 (consider using the np.arange() method from numpy to build out a sequence of values)\n",
    "\n",
    "Note: Feel free to try out more parameters, the above is the bare minimum for this assignment.\n",
    "\n",
    "Use 5 cross-fold and the default scoring. Please set verbose = 0 to reduce the printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='linear', random_state=42),\n",
       "             param_grid={'C': array([0.01, 0.21, 0.41, 0.61, 0.81, 1.01, 1.21, 1.41, 1.61, 1.81, 2.01,\n",
       "       2.21, 2.41, 2.61, 2.81, 3.01, 3.21, 3.41, 3.61, 3.81, 4.01, 4.21,\n",
       "       4.41, 4.61, 4.81, 5.01, 5.21, 5.41, 5.61, 5.81, 6.01, 6.21, 6.41,\n",
       "       6.61, 6.81, 7.01, 7.21, 7.41, 7.61, 7.81, 8.01, 8.21, 8.41, 8.61,\n",
       "       8.81, 9.01, 9.21, 9.41, 9.61, 9.81])})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': np.arange(0.01, 10, 0.2)}\n",
    "svc_l = SVC(kernel='linear', random_state=42)\n",
    "svc_l_gs = GridSearchCV(svc_l, param_grid, cv=5, verbose=0)\n",
    "svc_l_gs.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Identify the best performing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.01, kernel='linear', random_state=42) {'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(svc_l_gs.best_estimator_, svc_l_gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Use the best estimator model to predict on test data. Use the .predict() method to get the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['car ', 'concrete ', 'building ', 'concrete ', 'concrete ',\n",
       "       'tree ', 'car ', 'car ', 'building ', 'tree ', 'building ',\n",
       "       'asphalt ', 'building ', 'grass ', 'shadow ', 'building ', 'tree ',\n",
       "       'concrete ', 'building ', 'shadow ', 'pool ', 'asphalt ',\n",
       "       'concrete ', 'tree ', 'grass ', 'concrete ', 'grass ', 'building ',\n",
       "       'building ', 'building ', 'asphalt ', 'shadow ', 'concrete ',\n",
       "       'grass ', 'tree ', 'concrete ', 'asphalt ', 'concrete ', 'tree ',\n",
       "       'concrete ', 'concrete ', 'tree ', 'building ', 'building ',\n",
       "       'building ', 'grass ', 'grass ', 'shadow ', 'concrete ', 'soil ',\n",
       "       'shadow ', 'tree ', 'car ', 'car ', 'shadow ', 'pool ',\n",
       "       'building ', 'tree ', 'grass ', 'grass ', 'car ', 'car ', 'pool ',\n",
       "       'building ', 'soil ', 'grass ', 'building ', 'concrete ',\n",
       "       'building ', 'soil ', 'concrete ', 'building ', 'shadow ', 'pool ',\n",
       "       'pool ', 'shadow ', 'building ', 'grass ', 'shadow ', 'building ',\n",
       "       'pool ', 'pool ', 'building ', 'building ', 'building ', 'shadow ',\n",
       "       'building ', 'grass ', 'asphalt ', 'grass ', 'grass ', 'grass ',\n",
       "       'concrete ', 'concrete ', 'concrete ', 'grass ', 'pool ', 'car ',\n",
       "       'shadow ', 'tree ', 'grass ', 'asphalt ', 'tree ', 'car ', 'tree ',\n",
       "       'asphalt ', 'grass ', 'building ', 'soil ', 'grass ', 'asphalt ',\n",
       "       'grass ', 'grass ', 'pool ', 'concrete ', 'tree ', 'grass ',\n",
       "       'concrete ', 'concrete ', 'car ', 'car ', 'grass ', 'shadow ',\n",
       "       'pool ', 'tree ', 'asphalt ', 'grass ', 'building ', 'building ',\n",
       "       'grass ', 'concrete ', 'asphalt ', 'asphalt ', 'concrete ',\n",
       "       'asphalt ', 'grass ', 'asphalt ', 'pool ', 'pool ', 'pool ',\n",
       "       'car ', 'grass ', 'concrete ', 'asphalt ', 'concrete ', 'asphalt ',\n",
       "       'building ', 'shadow ', 'shadow ', 'tree ', 'concrete ', 'car ',\n",
       "       'tree ', 'shadow ', 'concrete ', 'building ', 'concrete ', 'tree ',\n",
       "       'asphalt ', 'concrete ', 'grass ', 'tree ', 'tree ', 'car ',\n",
       "       'soil ', 'grass ', 'grass ', 'concrete '], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_svc_l = svc_l_gs.best_estimator_.predict(X_test_scaled)\n",
    "y_pred_svc_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Calculate the confusion matrix and classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0, 22,  0,  2,  1,  0,  0,  0,  0],\n",
       "       [ 0,  1, 14,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  3,  0, 19,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  1, 25,  0,  0,  0,  3],\n",
       "       [ 0,  1,  0,  0,  0, 13,  1,  0,  0],\n",
       "       [ 3,  0,  0,  0,  0,  0, 13,  0,  0],\n",
       "       [ 0,  1,  0,  6,  3,  0,  0,  4,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  0, 16]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_svc_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.81      0.93      0.87        14\n",
      "   building        0.79      0.88      0.83        25\n",
      "        car        1.00      0.93      0.97        15\n",
      "   concrete        0.66      0.83      0.73        23\n",
      "      grass        0.86      0.86      0.86        29\n",
      "       pool        1.00      0.87      0.93        15\n",
      "     shadow        0.87      0.81      0.84        16\n",
      "       soil        0.80      0.29      0.42        14\n",
      "       tree        0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.83       168\n",
      "   macro avg       0.85      0.82      0.81       168\n",
      "weighted avg       0.84      0.83      0.82       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svc_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e)  Calculate predictions for the training data & build the classification report & confusion matrix. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0,  0,  0,  0,  0,  5,  0,  0],\n",
       "       [ 2, 87,  0,  7,  0,  0,  1,  0,  0],\n",
       "       [ 0,  1, 19,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  9,  0, 83,  1,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0, 70,  0,  0,  0, 12],\n",
       "       [ 0,  1,  0,  0,  1, 12,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0, 43,  0,  1],\n",
       "       [ 0,  3,  0,  4,  2,  0,  0, 11,  0],\n",
       "       [ 0,  0,  0,  0,  3,  0,  1,  0, 85]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_svc_l_train = svc_l_gs.best_estimator_.predict(X_train_scaled)\n",
    "confusion_matrix(y_train, y_pred_svc_l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.93      0.89      0.91        45\n",
      "   building        0.85      0.90      0.87        97\n",
      "        car        1.00      0.90      0.95        21\n",
      "   concrete        0.87      0.89      0.88        93\n",
      "      grass        0.91      0.84      0.88        83\n",
      "       pool        1.00      0.86      0.92        14\n",
      "     shadow        0.86      0.96      0.91        45\n",
      "       soil        1.00      0.55      0.71        20\n",
      "       tree        0.87      0.96      0.91        89\n",
      "\n",
      "    accuracy                           0.89       507\n",
      "   macro avg       0.92      0.86      0.88       507\n",
      "weighted avg       0.89      0.89      0.89       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_svc_l_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't overfitting, while the model does perform better on the training set, it perfrms similarily on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Support Vector Machine Classifier + Polynomial Kernel + Grid Search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use GridSearchCV to try various hyperparameters in a SVM with a polynomial kernel.<br>\n",
    "\n",
    "a) Use SVC from sklearn with kernel = \"poly\". Run the GridSearchCV using the following:\n",
    "\n",
    "C: 0.01 - 10 in increments of 0.2\n",
    "degree: 2, 3, 4, 5, 6\n",
    "\n",
    "Note: Feel free to try out more parameters, the above is the bare minimum for this assignment.\n",
    "\n",
    "Use 5 cross-fold and the default scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='poly', random_state=42),\n",
       "             param_grid={'C': array([0.01, 0.21, 0.41, 0.61, 0.81, 1.01, 1.21, 1.41, 1.61, 1.81, 2.01,\n",
       "       2.21, 2.41, 2.61, 2.81, 3.01, 3.21, 3.41, 3.61, 3.81, 4.01, 4.21,\n",
       "       4.41, 4.61, 4.81, 5.01, 5.21, 5.41, 5.61, 5.81, 6.01, 6.21, 6.41,\n",
       "       6.61, 6.81, 7.01, 7.21, 7.41, 7.61, 7.81, 8.01, 8.21, 8.41, 8.61,\n",
       "       8.81, 9.01, 9.21, 9.41, 9.61, 9.81]),\n",
       "                         'degree': [2, 3, 4, 5, 6]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': np.arange(0.01, 10, 0.2), 'degree': [2, 3, 4, 5, 6]}\n",
    "svc_p = SVC(kernel='poly', random_state=42)\n",
    "svc_poly = GridSearchCV(svc_p, param_grid, cv=5, verbose=0)\n",
    "svc_poly.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Identify the best performing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=3.81, kernel='poly', random_state=42) {'C': 3.81, 'degree': 3}\n"
     ]
    }
   ],
   "source": [
    "print(svc_poly.best_estimator_, svc_poly.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Use the best estimator model to predict on test data. Use the .predict() method to get the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['soil ', 'concrete ', 'building ', 'concrete ', 'concrete ',\n",
       "       'grass ', 'car ', 'car ', 'building ', 'tree ', 'building ',\n",
       "       'asphalt ', 'building ', 'soil ', 'shadow ', 'building ', 'tree ',\n",
       "       'concrete ', 'building ', 'shadow ', 'pool ', 'asphalt ',\n",
       "       'concrete ', 'grass ', 'grass ', 'concrete ', 'grass ',\n",
       "       'building ', 'grass ', 'building ', 'asphalt ', 'shadow ',\n",
       "       'concrete ', 'grass ', 'tree ', 'concrete ', 'asphalt ',\n",
       "       'concrete ', 'grass ', 'concrete ', 'concrete ', 'tree ',\n",
       "       'building ', 'building ', 'building ', 'grass ', 'grass ',\n",
       "       'shadow ', 'grass ', 'grass ', 'shadow ', 'tree ', 'car ', 'car ',\n",
       "       'shadow ', 'pool ', 'building ', 'tree ', 'grass ', 'grass ',\n",
       "       'car ', 'car ', 'pool ', 'building ', 'grass ', 'grass ',\n",
       "       'building ', 'concrete ', 'building ', 'grass ', 'concrete ',\n",
       "       'building ', 'shadow ', 'pool ', 'pool ', 'shadow ', 'building ',\n",
       "       'grass ', 'shadow ', 'building ', 'building ', 'pool ',\n",
       "       'building ', 'building ', 'concrete ', 'shadow ', 'concrete ',\n",
       "       'grass ', 'asphalt ', 'grass ', 'grass ', 'grass ', 'concrete ',\n",
       "       'concrete ', 'concrete ', 'grass ', 'pool ', 'car ', 'shadow ',\n",
       "       'tree ', 'grass ', 'asphalt ', 'grass ', 'car ', 'tree ',\n",
       "       'asphalt ', 'grass ', 'grass ', 'concrete ', 'grass ', 'asphalt ',\n",
       "       'grass ', 'grass ', 'pool ', 'concrete ', 'tree ', 'grass ',\n",
       "       'concrete ', 'concrete ', 'car ', 'car ', 'grass ', 'shadow ',\n",
       "       'building ', 'tree ', 'tree ', 'grass ', 'building ', 'building ',\n",
       "       'grass ', 'concrete ', 'asphalt ', 'asphalt ', 'concrete ',\n",
       "       'asphalt ', 'grass ', 'shadow ', 'pool ', 'building ', 'pool ',\n",
       "       'building ', 'grass ', 'grass ', 'asphalt ', 'concrete ',\n",
       "       'asphalt ', 'building ', 'shadow ', 'shadow ', 'tree ', 'grass ',\n",
       "       'pool ', 'tree ', 'shadow ', 'concrete ', 'building ', 'concrete ',\n",
       "       'tree ', 'asphalt ', 'concrete ', 'grass ', 'tree ', 'tree ',\n",
       "       'car ', 'grass ', 'grass ', 'grass ', 'concrete '], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_poly = svc_poly.best_estimator_.predict(X_test_scaled)\n",
    "y_pred_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Calculate the confusion matrix and classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0, 18,  0,  4,  3,  0,  0,  0,  0],\n",
       "       [ 0,  2, 11,  0,  0,  1,  0,  1,  0],\n",
       "       [ 0,  3,  0, 19,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 26,  0,  0,  1,  2],\n",
       "       [ 0,  4,  0,  0,  0, 10,  1,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0, 14,  0,  1],\n",
       "       [ 0,  1,  0,  5,  8,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  3,  0,  0,  0, 13]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.93      0.93      0.93        14\n",
      "   building        0.64      0.72      0.68        25\n",
      "        car        1.00      0.73      0.85        15\n",
      "   concrete        0.66      0.83      0.73        23\n",
      "      grass        0.63      0.90      0.74        29\n",
      "       pool        0.91      0.67      0.77        15\n",
      "     shadow        0.88      0.88      0.88        16\n",
      "       soil        0.00      0.00      0.00        14\n",
      "       tree        0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.74       168\n",
      "   macro avg       0.72      0.71      0.71       168\n",
      "weighted avg       0.71      0.74      0.71       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e)  Calculate predictions for the training data & build the classification report & confusion matrix. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44,  0,  0,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0, 95,  0,  1,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0, 20,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0, 91,  1,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0, 81,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  1, 13,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 45,  0,  0],\n",
       "       [ 0,  0,  0,  0, 11,  0,  0,  9,  0],\n",
       "       [ 0,  0,  0,  0,  5,  0,  0,  0, 84]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train_poly = svc_poly.best_estimator_.predict(X_train_scaled)\n",
    "confusion_matrix(y_train, y_pred_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      0.98      0.99        45\n",
      "   building        0.98      0.98      0.98        97\n",
      "        car        1.00      0.95      0.98        21\n",
      "   concrete        0.99      0.98      0.98        93\n",
      "      grass        0.79      0.98      0.88        83\n",
      "       pool        1.00      0.93      0.96        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      0.45      0.62        20\n",
      "       tree        0.99      0.94      0.97        89\n",
      "\n",
      "    accuracy                           0.95       507\n",
      "   macro avg       0.97      0.91      0.93       507\n",
      "weighted avg       0.96      0.95      0.95       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are signs of overfitting as it can be seen that the precision, recall and f1-scores are much better for the train data than the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Support Vector Machine Classifier + RBF Kernel + Grid Search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use GridSearchCV to try various hyperparameters in a SVM with a RBF kernel.<br>\n",
    "\n",
    "a) Use SVC from sklearn with kernel = \"rbf\". Run the GridSearchCV using the following:\n",
    "\n",
    "C: 0.01 - 10 in increments of 0.2\n",
    "gamma: 0.01,  0.1, 1, 10, 100\n",
    "\n",
    "Note: Feel free to try out more parameters, the above is the bare minimum for this assignment.\n",
    "\n",
    "Use 5 cross-fold and the default scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(random_state=42),\n",
       "             param_grid={'C': array([0.01, 0.21, 0.41, 0.61, 0.81, 1.01, 1.21, 1.41, 1.61, 1.81, 2.01,\n",
       "       2.21, 2.41, 2.61, 2.81, 3.01, 3.21, 3.41, 3.61, 3.81, 4.01, 4.21,\n",
       "       4.41, 4.61, 4.81, 5.01, 5.21, 5.41, 5.61, 5.81, 6.01, 6.21, 6.41,\n",
       "       6.61, 6.81, 7.01, 7.21, 7.41, 7.61, 7.81, 8.01, 8.21, 8.41, 8.61,\n",
       "       8.81, 9.01, 9.21, 9.41, 9.61, 9.81]),\n",
       "                         'gamma': [0.01, 0.1, 1, 10, 100]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': np.arange(0.01, 10, 0.2), 'gamma': [0.01, 0.1, 1, 10, 100]}\n",
    "svc_r = SVC(kernel='rbf', random_state=42)\n",
    "svc_rbf = GridSearchCV(svc_r, param_grid, cv=5, verbose=0)\n",
    "svc_rbf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Identify the best performing model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=2.81, gamma=0.01, random_state=42) {'C': 2.81, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(svc_rbf.best_estimator_, svc_rbf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Use the best estimator model to predict on test data. Use the .predict() method to get the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['car ', 'concrete ', 'building ', 'concrete ', 'concrete ',\n",
       "       'tree ', 'car ', 'car ', 'building ', 'tree ', 'building ',\n",
       "       'asphalt ', 'building ', 'building ', 'shadow ', 'building ',\n",
       "       'tree ', 'concrete ', 'building ', 'shadow ', 'pool ', 'asphalt ',\n",
       "       'concrete ', 'tree ', 'grass ', 'concrete ', 'grass ', 'building ',\n",
       "       'building ', 'building ', 'asphalt ', 'shadow ', 'concrete ',\n",
       "       'grass ', 'tree ', 'concrete ', 'asphalt ', 'concrete ', 'tree ',\n",
       "       'concrete ', 'concrete ', 'tree ', 'building ', 'building ',\n",
       "       'building ', 'grass ', 'grass ', 'shadow ', 'soil ', 'soil ',\n",
       "       'shadow ', 'tree ', 'car ', 'car ', 'shadow ', 'pool ',\n",
       "       'building ', 'tree ', 'grass ', 'grass ', 'car ', 'car ', 'pool ',\n",
       "       'car ', 'soil ', 'grass ', 'building ', 'concrete ', 'building ',\n",
       "       'soil ', 'concrete ', 'building ', 'shadow ', 'pool ', 'pool ',\n",
       "       'concrete ', 'building ', 'grass ', 'shadow ', 'building ',\n",
       "       'pool ', 'pool ', 'building ', 'building ', 'concrete ', 'shadow ',\n",
       "       'concrete ', 'grass ', 'asphalt ', 'grass ', 'grass ', 'grass ',\n",
       "       'concrete ', 'concrete ', 'concrete ', 'grass ', 'pool ', 'car ',\n",
       "       'shadow ', 'tree ', 'grass ', 'asphalt ', 'tree ', 'car ', 'tree ',\n",
       "       'asphalt ', 'grass ', 'building ', 'concrete ', 'grass ',\n",
       "       'asphalt ', 'grass ', 'grass ', 'pool ', 'concrete ', 'tree ',\n",
       "       'grass ', 'concrete ', 'concrete ', 'car ', 'concrete ', 'tree ',\n",
       "       'shadow ', 'pool ', 'tree ', 'shadow ', 'grass ', 'pool ',\n",
       "       'building ', 'grass ', 'concrete ', 'asphalt ', 'asphalt ',\n",
       "       'concrete ', 'asphalt ', 'grass ', 'shadow ', 'pool ', 'pool ',\n",
       "       'pool ', 'car ', 'grass ', 'concrete ', 'asphalt ', 'concrete ',\n",
       "       'asphalt ', 'building ', 'shadow ', 'shadow ', 'tree ', 'grass ',\n",
       "       'car ', 'tree ', 'shadow ', 'concrete ', 'concrete ', 'concrete ',\n",
       "       'tree ', 'asphalt ', 'concrete ', 'grass ', 'tree ', 'tree ',\n",
       "       'car ', 'soil ', 'grass ', 'grass ', 'concrete '], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rbf = svc_rbf.best_estimator_.predict(X_test_scaled)\n",
    "y_pred_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Calculate the confusion matrix and classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0, 19,  0,  5,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0, 14,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  3,  0, 20,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0, 24,  0,  0,  0,  4],\n",
       "       [ 0,  0,  0,  0,  0, 14,  1,  0,  0],\n",
       "       [ 1,  0,  0,  1,  0,  0, 14,  0,  0],\n",
       "       [ 0,  1,  0,  5,  3,  0,  0,  5,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  0, 16]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        0.93      0.93      0.93        14\n",
      "   building        0.79      0.76      0.78        25\n",
      "        car        1.00      0.93      0.97        15\n",
      "   concrete        0.61      0.87      0.71        23\n",
      "      grass        0.86      0.83      0.84        29\n",
      "       pool        1.00      0.93      0.97        15\n",
      "     shadow        0.88      0.88      0.88        16\n",
      "       soil        1.00      0.36      0.53        14\n",
      "       tree        0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.83       168\n",
      "   macro avg       0.87      0.83      0.83       168\n",
      "weighted avg       0.85      0.83      0.82       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e)  Calculate predictions for the training data & build the classification report & confusion matrix. Are there signs of overfitting? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 96,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 21,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0, 92,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0, 81,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0, 14,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 45,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0, 19,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  0, 88]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train_rbf = svc_rbf.best_estimator_.predict(X_train_scaled)\n",
    "confusion_matrix(y_train, y_pred_train_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    asphalt        1.00      1.00      1.00        45\n",
      "   building        0.97      0.99      0.98        97\n",
      "        car        1.00      1.00      1.00        21\n",
      "   concrete        0.99      0.99      0.99        93\n",
      "      grass        0.99      0.98      0.98        83\n",
      "       pool        1.00      1.00      1.00        14\n",
      "     shadow        1.00      1.00      1.00        45\n",
      "       soil        1.00      0.95      0.97        20\n",
      "       tree        0.99      0.99      0.99        89\n",
      "\n",
      "    accuracy                           0.99       507\n",
      "   macro avg       0.99      0.99      0.99       507\n",
      "weighted avg       0.99      0.99      0.99       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are signs of overfitting as it can be seen that while the precision and recall are high in the train data, it is drastically different for in the test data as seen in the classes concrete and building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conceptual Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) From the models run in steps 2-6, which performs the best based on the Classification Report? Support your reasoning with evidence around your test data.<br>\n",
    "Based on the classification report, I believe SVM with Linear Kernel is the best as it's precision and recall are the best values and there is no overfitting in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Compare models run for steps 4-6 where different kernels were used. What is the benefit of using a polynomial or rbf kernel over a linear kernel? What could be a downside of using a polynomial or rbf kernel? <br>\n",
    "- The benefit of using a polynomial or RBF kernel over a linear kernel is that these kernels can capture non-linear relationships between the features and can result in higher accuracy on complex datasets where the decision boundary is non-linear.\n",
    "- The downside of using a polynomial or RBF kernel is that they can be more computationally intensive than a linear kernel and may require more tuning of the hyperparameters. \n",
    "    - The polynomial kernel can be sensitive to the choice of degree and can result in overfitting if the degree is too high. \n",
    "    - Similarly, the RBF kernel can be sensitive to the choice of the gamma hyperparameter, which controls the shape of the decision boundary, and can result in overfitting if gamma is too small or too large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Explain the 'C' parameter used in steps 4-6. What does a small C mean versus a large C in sklearn? Why is it important to use the 'C' parameter when fitting a model?<br>\n",
    "The 'C' parameter used in steps 4-6 is the regularizaton parameter. The strength of the regularization is inversely proportional to C. It determines the penalty which is a squared l2 penalty for misclassifications of training data. \n",
    "- A small C value means that the model is less sensitive to misclassifications in the training data, which can result in a more generalizable model that performs better on new, unseen data. \n",
    "- A large C value means that the model is more sensitive to misclassifications in the training data and may result in a model that overfits the training data and does not generalize well to new data.\n",
    "As explained in the above two points, it is important to use the C parameter when fitting an SVM model because it controls the trade-off between overfitting and underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Scaling our input data does not matter much for Random Forest, but it is a critical step for Support Vector Machines. Explain why this is such a critical step. Also, provide an example of a feature from this data set that could cause issues with our SVMs if not scaled.<br>\n",
    "Scaling the input data is critical for SVMs but not for Random Forest because SVMs are sensitive to the scale of the input features. SVMs aim to find the decision boundary that maximizes the margin between the support vectors and the decision boundary, and if the features are on different scales, the decision boundary may be influenced more by features with larger scales than features with smaller scales. On the other hand, Random Forest makes no assumptions about the distribution of the input features and is less sensitive to differences in scale between features.<br>\n",
    "An example of a feature from the dataset used in this notebook that could cause issues with SVMs if not scaled is the 'Area' feature, which measures the area of the land in meters. The range of this feature is much larger than the other features like Rect_100, NDVI_100, etc in the dataset. If we do not scale the data, the SVM algorithm may give more weight to the Area feature when constructing the decision boundary, even though other features may be more important predictors of the outcome variable. This can result in a biased model that does not accurately reflect the relationship between the input and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>SD_G</th>\n",
       "      <th>SD_R</th>\n",
       "      <th>SD_NIR</th>\n",
       "      <th>LW</th>\n",
       "      <th>GLCM1</th>\n",
       "      <th>Rect</th>\n",
       "      <th>GLCM2</th>\n",
       "      <th>Dens</th>\n",
       "      <th>Assym</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>BordLngth</th>\n",
       "      <th>GLCM3</th>\n",
       "      <th>BrdIndx_40</th>\n",
       "      <th>Area_40</th>\n",
       "      <th>Round_40</th>\n",
       "      <th>Bright_40</th>\n",
       "      <th>Compact_40</th>\n",
       "      <th>ShpIndx_40</th>\n",
       "      <th>Mean_G_40</th>\n",
       "      <th>Mean_R_40</th>\n",
       "      <th>Mean_NIR_40</th>\n",
       "      <th>SD_G_40</th>\n",
       "      <th>SD_R_40</th>\n",
       "      <th>SD_NIR_40</th>\n",
       "      <th>LW_40</th>\n",
       "      <th>GLCM1_40</th>\n",
       "      <th>Rect_40</th>\n",
       "      <th>GLCM2_40</th>\n",
       "      <th>Dens_40</th>\n",
       "      <th>Assym_40</th>\n",
       "      <th>NDVI_40</th>\n",
       "      <th>BordLngth_40</th>\n",
       "      <th>GLCM3_40</th>\n",
       "      <th>BrdIndx_60</th>\n",
       "      <th>Area_60</th>\n",
       "      <th>Round_60</th>\n",
       "      <th>Bright_60</th>\n",
       "      <th>Compact_60</th>\n",
       "      <th>ShpIndx_60</th>\n",
       "      <th>Mean_G_60</th>\n",
       "      <th>Mean_R_60</th>\n",
       "      <th>Mean_NIR_60</th>\n",
       "      <th>SD_G_60</th>\n",
       "      <th>SD_R_60</th>\n",
       "      <th>SD_NIR_60</th>\n",
       "      <th>LW_60</th>\n",
       "      <th>GLCM1_60</th>\n",
       "      <th>Rect_60</th>\n",
       "      <th>GLCM2_60</th>\n",
       "      <th>Dens_60</th>\n",
       "      <th>Assym_60</th>\n",
       "      <th>NDVI_60</th>\n",
       "      <th>BordLngth_60</th>\n",
       "      <th>GLCM3_60</th>\n",
       "      <th>BrdIndx_80</th>\n",
       "      <th>Area_80</th>\n",
       "      <th>Round_80</th>\n",
       "      <th>Bright_80</th>\n",
       "      <th>Compact_80</th>\n",
       "      <th>ShpIndx_80</th>\n",
       "      <th>Mean_G_80</th>\n",
       "      <th>Mean_R_80</th>\n",
       "      <th>Mean_NIR_80</th>\n",
       "      <th>SD_G_80</th>\n",
       "      <th>SD_R_80</th>\n",
       "      <th>SD_NIR_80</th>\n",
       "      <th>LW_80</th>\n",
       "      <th>GLCM1_80</th>\n",
       "      <th>Rect_80</th>\n",
       "      <th>GLCM2_80</th>\n",
       "      <th>Dens_80</th>\n",
       "      <th>Assym_80</th>\n",
       "      <th>NDVI_80</th>\n",
       "      <th>BordLngth_80</th>\n",
       "      <th>GLCM3_80</th>\n",
       "      <th>BrdIndx_100</th>\n",
       "      <th>Area_100</th>\n",
       "      <th>Round_100</th>\n",
       "      <th>Bright_100</th>\n",
       "      <th>Compact_100</th>\n",
       "      <th>ShpIndx_100</th>\n",
       "      <th>Mean_G_100</th>\n",
       "      <th>Mean_R_100</th>\n",
       "      <th>Mean_NIR_100</th>\n",
       "      <th>SD_G_100</th>\n",
       "      <th>SD_R_100</th>\n",
       "      <th>SD_NIR_100</th>\n",
       "      <th>LW_100</th>\n",
       "      <th>GLCM1_100</th>\n",
       "      <th>Rect_100</th>\n",
       "      <th>GLCM2_100</th>\n",
       "      <th>Dens_100</th>\n",
       "      <th>Assym_100</th>\n",
       "      <th>NDVI_100</th>\n",
       "      <th>BordLngth_100</th>\n",
       "      <th>GLCM3_100</th>\n",
       "      <th>BrdIndx_120</th>\n",
       "      <th>Area_120</th>\n",
       "      <th>Round_120</th>\n",
       "      <th>Bright_120</th>\n",
       "      <th>Compact_120</th>\n",
       "      <th>ShpIndx_120</th>\n",
       "      <th>Mean_G_120</th>\n",
       "      <th>Mean_R_120</th>\n",
       "      <th>Mean_NIR_120</th>\n",
       "      <th>SD_G_120</th>\n",
       "      <th>SD_R_120</th>\n",
       "      <th>SD_NIR_120</th>\n",
       "      <th>LW_120</th>\n",
       "      <th>GLCM1_120</th>\n",
       "      <th>Rect_120</th>\n",
       "      <th>GLCM2_120</th>\n",
       "      <th>Dens_120</th>\n",
       "      <th>Assym_120</th>\n",
       "      <th>NDVI_120</th>\n",
       "      <th>BordLngth_120</th>\n",
       "      <th>GLCM3_120</th>\n",
       "      <th>BrdIndx_140</th>\n",
       "      <th>Area_140</th>\n",
       "      <th>Round_140</th>\n",
       "      <th>Bright_140</th>\n",
       "      <th>Compact_140</th>\n",
       "      <th>ShpIndx_140</th>\n",
       "      <th>Mean_G_140</th>\n",
       "      <th>Mean_R_140</th>\n",
       "      <th>Mean_NIR_140</th>\n",
       "      <th>SD_G_140</th>\n",
       "      <th>SD_R_140</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concrete</td>\n",
       "      <td>1.32</td>\n",
       "      <td>131</td>\n",
       "      <td>0.81</td>\n",
       "      <td>222.74</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.18</td>\n",
       "      <td>192.94</td>\n",
       "      <td>235.11</td>\n",
       "      <td>240.15</td>\n",
       "      <td>11.24</td>\n",
       "      <td>11.47</td>\n",
       "      <td>11.24</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.78</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>100</td>\n",
       "      <td>4322.47</td>\n",
       "      <td>1.32</td>\n",
       "      <td>131</td>\n",
       "      <td>0.81</td>\n",
       "      <td>222.74</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.18</td>\n",
       "      <td>192.94</td>\n",
       "      <td>235.11</td>\n",
       "      <td>240.15</td>\n",
       "      <td>11.24</td>\n",
       "      <td>11.47</td>\n",
       "      <td>11.24</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.78</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>100</td>\n",
       "      <td>4322.47</td>\n",
       "      <td>1.19</td>\n",
       "      <td>452</td>\n",
       "      <td>0.49</td>\n",
       "      <td>196.82</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.46</td>\n",
       "      <td>169.60</td>\n",
       "      <td>208.71</td>\n",
       "      <td>212.17</td>\n",
       "      <td>18.48</td>\n",
       "      <td>20.90</td>\n",
       "      <td>22.09</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.44</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>124</td>\n",
       "      <td>2271.21</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1522</td>\n",
       "      <td>2.70</td>\n",
       "      <td>181.04</td>\n",
       "      <td>5.48</td>\n",
       "      <td>3.69</td>\n",
       "      <td>155.76</td>\n",
       "      <td>192.34</td>\n",
       "      <td>195.03</td>\n",
       "      <td>34.93</td>\n",
       "      <td>39.49</td>\n",
       "      <td>39.17</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>576</td>\n",
       "      <td>1789.91</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1522</td>\n",
       "      <td>2.70</td>\n",
       "      <td>181.04</td>\n",
       "      <td>5.48</td>\n",
       "      <td>3.69</td>\n",
       "      <td>155.76</td>\n",
       "      <td>192.34</td>\n",
       "      <td>195.03</td>\n",
       "      <td>34.93</td>\n",
       "      <td>39.49</td>\n",
       "      <td>39.17</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>576</td>\n",
       "      <td>1789.91</td>\n",
       "      <td>2.75</td>\n",
       "      <td>7618</td>\n",
       "      <td>2.43</td>\n",
       "      <td>189.73</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.40</td>\n",
       "      <td>163.61</td>\n",
       "      <td>201.29</td>\n",
       "      <td>204.28</td>\n",
       "      <td>25.25</td>\n",
       "      <td>28.33</td>\n",
       "      <td>28.30</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.35</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1188</td>\n",
       "      <td>1298.99</td>\n",
       "      <td>2.93</td>\n",
       "      <td>9172</td>\n",
       "      <td>2.50</td>\n",
       "      <td>185.14</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.95</td>\n",
       "      <td>159.45</td>\n",
       "      <td>196.43</td>\n",
       "      <td>199.53</td>\n",
       "      <td>27.81</td>\n",
       "      <td>31.55</td>\n",
       "      <td>31.15</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1512</td>\n",
       "      <td>1287.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shadow</td>\n",
       "      <td>1.59</td>\n",
       "      <td>864</td>\n",
       "      <td>0.94</td>\n",
       "      <td>47.56</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.87</td>\n",
       "      <td>36.82</td>\n",
       "      <td>48.78</td>\n",
       "      <td>57.09</td>\n",
       "      <td>8.15</td>\n",
       "      <td>8.02</td>\n",
       "      <td>8.36</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>220</td>\n",
       "      <td>3331.33</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1353</td>\n",
       "      <td>0.46</td>\n",
       "      <td>49.12</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.33</td>\n",
       "      <td>38.29</td>\n",
       "      <td>50.40</td>\n",
       "      <td>58.67</td>\n",
       "      <td>8.84</td>\n",
       "      <td>9.97</td>\n",
       "      <td>10.55</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6.96</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>196</td>\n",
       "      <td>3063.33</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1377</td>\n",
       "      <td>0.46</td>\n",
       "      <td>49.82</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.32</td>\n",
       "      <td>38.88</td>\n",
       "      <td>51.21</td>\n",
       "      <td>59.38</td>\n",
       "      <td>10.07</td>\n",
       "      <td>11.89</td>\n",
       "      <td>12.01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>196</td>\n",
       "      <td>2659.74</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1377</td>\n",
       "      <td>0.46</td>\n",
       "      <td>49.82</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.32</td>\n",
       "      <td>38.88</td>\n",
       "      <td>51.21</td>\n",
       "      <td>59.38</td>\n",
       "      <td>10.07</td>\n",
       "      <td>11.89</td>\n",
       "      <td>12.01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>196</td>\n",
       "      <td>2659.74</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1377</td>\n",
       "      <td>0.46</td>\n",
       "      <td>49.82</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.32</td>\n",
       "      <td>38.88</td>\n",
       "      <td>51.21</td>\n",
       "      <td>59.38</td>\n",
       "      <td>10.07</td>\n",
       "      <td>11.89</td>\n",
       "      <td>12.01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>196</td>\n",
       "      <td>2659.74</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1377</td>\n",
       "      <td>0.46</td>\n",
       "      <td>49.82</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.32</td>\n",
       "      <td>38.88</td>\n",
       "      <td>51.21</td>\n",
       "      <td>59.38</td>\n",
       "      <td>10.07</td>\n",
       "      <td>11.89</td>\n",
       "      <td>12.01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>196</td>\n",
       "      <td>2659.74</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1377</td>\n",
       "      <td>0.46</td>\n",
       "      <td>49.82</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.32</td>\n",
       "      <td>38.88</td>\n",
       "      <td>51.21</td>\n",
       "      <td>59.38</td>\n",
       "      <td>10.07</td>\n",
       "      <td>11.89</td>\n",
       "      <td>12.01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>196</td>\n",
       "      <td>2659.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shadow</td>\n",
       "      <td>1.41</td>\n",
       "      <td>409</td>\n",
       "      <td>1.00</td>\n",
       "      <td>51.38</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.53</td>\n",
       "      <td>41.72</td>\n",
       "      <td>51.96</td>\n",
       "      <td>60.48</td>\n",
       "      <td>8.11</td>\n",
       "      <td>9.20</td>\n",
       "      <td>9.61</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.86</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>124</td>\n",
       "      <td>2816.16</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1094</td>\n",
       "      <td>1.91</td>\n",
       "      <td>49.05</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.98</td>\n",
       "      <td>40.06</td>\n",
       "      <td>50.07</td>\n",
       "      <td>57.02</td>\n",
       "      <td>10.54</td>\n",
       "      <td>10.81</td>\n",
       "      <td>11.55</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.93</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>262</td>\n",
       "      <td>2668.96</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2826</td>\n",
       "      <td>2.00</td>\n",
       "      <td>45.67</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.09</td>\n",
       "      <td>38.69</td>\n",
       "      <td>45.68</td>\n",
       "      <td>52.63</td>\n",
       "      <td>9.90</td>\n",
       "      <td>10.70</td>\n",
       "      <td>11.01</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>7.02</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>658</td>\n",
       "      <td>2289.55</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2901</td>\n",
       "      <td>2.00</td>\n",
       "      <td>46.57</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.79</td>\n",
       "      <td>40.01</td>\n",
       "      <td>46.34</td>\n",
       "      <td>53.36</td>\n",
       "      <td>14.49</td>\n",
       "      <td>11.78</td>\n",
       "      <td>12.31</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>602</td>\n",
       "      <td>1432.44</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2901</td>\n",
       "      <td>2.00</td>\n",
       "      <td>46.57</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.79</td>\n",
       "      <td>40.01</td>\n",
       "      <td>46.34</td>\n",
       "      <td>53.36</td>\n",
       "      <td>14.49</td>\n",
       "      <td>11.78</td>\n",
       "      <td>12.31</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>602</td>\n",
       "      <td>1432.44</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2901</td>\n",
       "      <td>2.00</td>\n",
       "      <td>46.57</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.79</td>\n",
       "      <td>40.01</td>\n",
       "      <td>46.34</td>\n",
       "      <td>53.36</td>\n",
       "      <td>14.49</td>\n",
       "      <td>11.78</td>\n",
       "      <td>12.31</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>602</td>\n",
       "      <td>1432.44</td>\n",
       "      <td>3.33</td>\n",
       "      <td>5932</td>\n",
       "      <td>1.69</td>\n",
       "      <td>55.06</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.89</td>\n",
       "      <td>59.76</td>\n",
       "      <td>48.66</td>\n",
       "      <td>56.76</td>\n",
       "      <td>30.65</td>\n",
       "      <td>18.59</td>\n",
       "      <td>18.75</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.63</td>\n",
       "      <td>8.32</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1198</td>\n",
       "      <td>720.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>2.58</td>\n",
       "      <td>187</td>\n",
       "      <td>1.91</td>\n",
       "      <td>70.08</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.11</td>\n",
       "      <td>93.13</td>\n",
       "      <td>55.20</td>\n",
       "      <td>61.92</td>\n",
       "      <td>28.60</td>\n",
       "      <td>15.88</td>\n",
       "      <td>15.09</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.50</td>\n",
       "      <td>7.28</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.26</td>\n",
       "      <td>170</td>\n",
       "      <td>2442.01</td>\n",
       "      <td>2.86</td>\n",
       "      <td>871</td>\n",
       "      <td>2.22</td>\n",
       "      <td>90.21</td>\n",
       "      <td>3.34</td>\n",
       "      <td>3.93</td>\n",
       "      <td>117.16</td>\n",
       "      <td>72.76</td>\n",
       "      <td>80.70</td>\n",
       "      <td>42.07</td>\n",
       "      <td>27.05</td>\n",
       "      <td>27.38</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>464</td>\n",
       "      <td>1234.84</td>\n",
       "      <td>2.86</td>\n",
       "      <td>871</td>\n",
       "      <td>2.22</td>\n",
       "      <td>90.21</td>\n",
       "      <td>3.34</td>\n",
       "      <td>3.93</td>\n",
       "      <td>117.16</td>\n",
       "      <td>72.76</td>\n",
       "      <td>80.70</td>\n",
       "      <td>42.07</td>\n",
       "      <td>27.05</td>\n",
       "      <td>27.38</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>464</td>\n",
       "      <td>1234.84</td>\n",
       "      <td>2.86</td>\n",
       "      <td>871</td>\n",
       "      <td>2.22</td>\n",
       "      <td>90.21</td>\n",
       "      <td>3.34</td>\n",
       "      <td>3.93</td>\n",
       "      <td>117.16</td>\n",
       "      <td>72.76</td>\n",
       "      <td>80.70</td>\n",
       "      <td>42.07</td>\n",
       "      <td>27.05</td>\n",
       "      <td>27.38</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>464</td>\n",
       "      <td>1234.84</td>\n",
       "      <td>2.18</td>\n",
       "      <td>1660</td>\n",
       "      <td>1.65</td>\n",
       "      <td>69.80</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.22</td>\n",
       "      <td>86.22</td>\n",
       "      <td>58.03</td>\n",
       "      <td>65.15</td>\n",
       "      <td>47.93</td>\n",
       "      <td>26.70</td>\n",
       "      <td>27.67</td>\n",
       "      <td>6.33</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.56</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>524</td>\n",
       "      <td>891.36</td>\n",
       "      <td>2.18</td>\n",
       "      <td>1660</td>\n",
       "      <td>1.65</td>\n",
       "      <td>69.80</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.22</td>\n",
       "      <td>86.22</td>\n",
       "      <td>58.03</td>\n",
       "      <td>65.15</td>\n",
       "      <td>47.93</td>\n",
       "      <td>26.70</td>\n",
       "      <td>27.67</td>\n",
       "      <td>6.33</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.56</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>524</td>\n",
       "      <td>891.36</td>\n",
       "      <td>2.18</td>\n",
       "      <td>1660</td>\n",
       "      <td>1.65</td>\n",
       "      <td>69.80</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.22</td>\n",
       "      <td>86.22</td>\n",
       "      <td>58.03</td>\n",
       "      <td>65.15</td>\n",
       "      <td>47.93</td>\n",
       "      <td>26.70</td>\n",
       "      <td>27.67</td>\n",
       "      <td>6.33</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.56</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>524</td>\n",
       "      <td>891.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asphalt</td>\n",
       "      <td>2.60</td>\n",
       "      <td>116</td>\n",
       "      <td>2.05</td>\n",
       "      <td>89.57</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.02</td>\n",
       "      <td>73.17</td>\n",
       "      <td>94.89</td>\n",
       "      <td>100.64</td>\n",
       "      <td>5.41</td>\n",
       "      <td>5.20</td>\n",
       "      <td>5.27</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.59</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>130</td>\n",
       "      <td>4912.28</td>\n",
       "      <td>4.02</td>\n",
       "      <td>501</td>\n",
       "      <td>2.33</td>\n",
       "      <td>100.69</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.40</td>\n",
       "      <td>83.66</td>\n",
       "      <td>106.21</td>\n",
       "      <td>112.19</td>\n",
       "      <td>15.39</td>\n",
       "      <td>16.50</td>\n",
       "      <td>16.44</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.45</td>\n",
       "      <td>7.28</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>394</td>\n",
       "      <td>2574.50</td>\n",
       "      <td>4.59</td>\n",
       "      <td>1367</td>\n",
       "      <td>1.91</td>\n",
       "      <td>113.93</td>\n",
       "      <td>3.07</td>\n",
       "      <td>4.65</td>\n",
       "      <td>98.87</td>\n",
       "      <td>118.98</td>\n",
       "      <td>123.95</td>\n",
       "      <td>25.07</td>\n",
       "      <td>23.28</td>\n",
       "      <td>22.31</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.15</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>688</td>\n",
       "      <td>1548.87</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1585</td>\n",
       "      <td>1.48</td>\n",
       "      <td>109.12</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.77</td>\n",
       "      <td>94.22</td>\n",
       "      <td>114.11</td>\n",
       "      <td>119.04</td>\n",
       "      <td>27.34</td>\n",
       "      <td>26.61</td>\n",
       "      <td>25.83</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>8.27</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>600</td>\n",
       "      <td>1396.74</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2351</td>\n",
       "      <td>1.05</td>\n",
       "      <td>96.24</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>82.84</td>\n",
       "      <td>100.31</td>\n",
       "      <td>105.55</td>\n",
       "      <td>30.51</td>\n",
       "      <td>32.60</td>\n",
       "      <td>32.05</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.62</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>496</td>\n",
       "      <td>1194.76</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2351</td>\n",
       "      <td>1.05</td>\n",
       "      <td>96.24</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>82.84</td>\n",
       "      <td>100.31</td>\n",
       "      <td>105.55</td>\n",
       "      <td>30.51</td>\n",
       "      <td>32.60</td>\n",
       "      <td>32.05</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.62</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>496</td>\n",
       "      <td>1194.76</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2351</td>\n",
       "      <td>1.05</td>\n",
       "      <td>96.24</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>82.84</td>\n",
       "      <td>100.31</td>\n",
       "      <td>105.55</td>\n",
       "      <td>30.51</td>\n",
       "      <td>32.60</td>\n",
       "      <td>32.05</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.62</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>496</td>\n",
       "      <td>1194.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  BrdIndx  Area  Round  Bright  Compact  ShpIndx  Mean_G  Mean_R  \\\n",
       "0  concrete      1.32   131   0.81  222.74     1.66     2.18  192.94  235.11   \n",
       "1    shadow      1.59   864   0.94   47.56     1.41     1.87   36.82   48.78   \n",
       "2    shadow      1.41   409   1.00   51.38     1.37     1.53   41.72   51.96   \n",
       "3      tree      2.58   187   1.91   70.08     3.41     3.11   93.13   55.20   \n",
       "4   asphalt      2.60   116   2.05   89.57     3.06     3.02   73.17   94.89   \n",
       "\n",
       "   Mean_NIR   SD_G   SD_R  SD_NIR    LW  GLCM1  Rect  GLCM2  Dens  Assym  \\\n",
       "0    240.15  11.24  11.47   11.24  8.18   0.43  0.78   6.64  0.87   0.99   \n",
       "1     57.09   8.15   8.02    8.36  3.05   0.43  0.85   6.75  1.81   0.73   \n",
       "2     60.48   8.11   9.20    9.61  1.94   0.54  0.86   6.51  1.82   0.69   \n",
       "3     61.92  28.60  15.88   15.09  3.23   0.73  0.50   7.28  1.03   0.89   \n",
       "4    100.64   5.41   5.20    5.27  2.30   0.43  0.59   6.02  1.23   0.82   \n",
       "\n",
       "   NDVI  BordLngth    GLCM3  BrdIndx_40  Area_40  Round_40  Bright_40  \\\n",
       "0 -0.10        100  4322.47        1.32      131      0.81     222.74   \n",
       "1 -0.14        220  3331.33        1.08     1353      0.46      49.12   \n",
       "2 -0.11        124  2816.16        1.75     1094      1.91      49.05   \n",
       "3  0.26        170  2442.01        2.86      871      2.22      90.21   \n",
       "4 -0.13        130  4912.28        4.02      501      2.33     100.69   \n",
       "\n",
       "   Compact_40  ShpIndx_40  Mean_G_40  Mean_R_40  Mean_NIR_40  SD_G_40  \\\n",
       "0        1.66        2.18     192.94     235.11       240.15    11.24   \n",
       "1        1.09        1.33      38.29      50.40        58.67     8.84   \n",
       "2        1.84        1.98      40.06      50.07        57.02    10.54   \n",
       "3        3.34        3.93     117.16      72.76        80.70    42.07   \n",
       "4        4.29        4.40      83.66     106.21       112.19    15.39   \n",
       "\n",
       "   SD_R_40  SD_NIR_40  LW_40  GLCM1_40  Rect_40  GLCM2_40  Dens_40  Assym_40  \\\n",
       "0    11.47      11.24   8.18      0.43     0.78      6.64     0.87      0.99   \n",
       "1     9.97      10.55   3.70      0.51     0.96      6.96     1.67      0.86   \n",
       "2    10.81      11.55   2.57      0.49     0.75      6.93     1.49      0.88   \n",
       "3    27.05      27.38   5.25      0.84     0.51      8.56     0.89      0.95   \n",
       "4    16.50      16.44   2.24      0.64     0.45      7.28     1.13      0.79   \n",
       "\n",
       "   NDVI_40  BordLngth_40  GLCM3_40  BrdIndx_60  Area_60  Round_60  Bright_60  \\\n",
       "0    -0.10           100   4322.47        1.19      452      0.49     196.82   \n",
       "1    -0.14           196   3063.33        1.07     1377      0.46      49.82   \n",
       "2    -0.11           262   2668.96        2.53     2826      2.00      45.67   \n",
       "3     0.23           464   1234.84        2.86      871      2.22      90.21   \n",
       "4    -0.12           394   2574.50        4.59     1367      1.91     113.93   \n",
       "\n",
       "   Compact_60  ShpIndx_60  Mean_G_60  Mean_R_60  Mean_NIR_60  SD_G_60  \\\n",
       "0        1.27        1.46     169.60     208.71       212.17    18.48   \n",
       "1        1.07        1.32      38.88      51.21        59.38    10.07   \n",
       "2        2.85        3.09      38.69      45.68        52.63     9.90   \n",
       "3        3.34        3.93     117.16      72.76        80.70    42.07   \n",
       "4        3.07        4.65      98.87     118.98       123.95    25.07   \n",
       "\n",
       "   SD_R_60  SD_NIR_60  LW_60  GLCM1_60  Rect_60  GLCM2_60  Dens_60  Assym_60  \\\n",
       "0    20.90      22.09   3.47      0.71     0.92      7.44     1.56      0.87   \n",
       "1    11.89      12.01   3.70      0.52     0.96      7.01     1.69      0.86   \n",
       "2    10.70      11.01   3.58      0.61     0.59      7.02     1.14      0.93   \n",
       "3    27.05      27.38   5.25      0.84     0.51      8.56     0.89      0.95   \n",
       "4    23.28      22.31   1.10      0.77     0.58      8.15     1.63      0.19   \n",
       "\n",
       "   NDVI_60  BordLngth_60  GLCM3_60  BrdIndx_80  Area_80  Round_80  Bright_80  \\\n",
       "0    -0.10           124   2271.21        3.65     1522      2.70     181.04   \n",
       "1    -0.14           196   2659.74        1.07     1377      0.46      49.82   \n",
       "2    -0.08           658   2289.55        2.30     2901      2.00      46.57   \n",
       "3     0.23           464   1234.84        2.86      871      2.22      90.21   \n",
       "4    -0.09           688   1548.87        3.70     1585      1.48     109.12   \n",
       "\n",
       "   Compact_80  ShpIndx_80  Mean_G_80  Mean_R_80  Mean_NIR_80  SD_G_80  \\\n",
       "0        5.48        3.69     155.76     192.34       195.03    34.93   \n",
       "1        1.07        1.32      38.88      51.21        59.38    10.07   \n",
       "2        2.78        2.79      40.01      46.34        53.36    14.49   \n",
       "3        3.34        3.93     117.16      72.76        80.70    42.07   \n",
       "4        2.70        3.77      94.22     114.11       119.04    27.34   \n",
       "\n",
       "   SD_R_80  SD_NIR_80  LW_80  GLCM1_80  Rect_80  GLCM2_80  Dens_80  Assym_80  \\\n",
       "0    39.49      39.17   1.13      0.73     0.28      8.40     1.21      0.23   \n",
       "1    11.89      12.01   3.70      0.52     0.96      7.01     1.69      0.86   \n",
       "2    11.78      12.31   3.57      0.65     0.60      7.11     1.16      0.93   \n",
       "3    27.05      27.38   5.25      0.84     0.51      8.56     0.89      0.95   \n",
       "4    26.61      25.83   1.08      0.79     0.71      8.27     1.83      0.20   \n",
       "\n",
       "   NDVI_80  BordLngth_80  GLCM3_80  BrdIndx_100  Area_100  Round_100  \\\n",
       "0    -0.11           576   1789.91         3.65      1522       2.70   \n",
       "1    -0.14           196   2659.74         1.07      1377       0.46   \n",
       "2    -0.07           602   1432.44         2.30      2901       2.00   \n",
       "3     0.23           464   1234.84         2.18      1660       1.65   \n",
       "4    -0.10           600   1396.74         2.53      2351       1.05   \n",
       "\n",
       "   Bright_100  Compact_100  ShpIndx_100  Mean_G_100  Mean_R_100  Mean_NIR_100  \\\n",
       "0      181.04         5.48         3.69      155.76      192.34        195.03   \n",
       "1       49.82         1.07         1.32       38.88       51.21         59.38   \n",
       "2       46.57         2.78         2.79       40.01       46.34         53.36   \n",
       "3       69.80         2.20         3.22       86.22       58.03         65.15   \n",
       "4       96.24         2.00         2.56       82.84      100.31        105.55   \n",
       "\n",
       "   SD_G_100  SD_R_100  SD_NIR_100  LW_100  GLCM1_100  Rect_100  GLCM2_100  \\\n",
       "0     34.93     39.49       39.17    1.13       0.73      0.28       8.40   \n",
       "1     10.07     11.89       12.01    3.70       0.52      0.96       7.01   \n",
       "2     14.49     11.78       12.31    3.57       0.65      0.60       7.11   \n",
       "3     47.93     26.70       27.67    6.33       0.89      0.70       8.56   \n",
       "4     30.51     32.60       32.05    1.01       0.83      0.75       8.62   \n",
       "\n",
       "   Dens_100  Assym_100  NDVI_100  BordLngth_100  GLCM3_100  BrdIndx_120  \\\n",
       "0      1.21       0.23     -0.11            576    1789.91         2.75   \n",
       "1      1.69       0.86     -0.14            196    2659.74         1.07   \n",
       "2      1.16       0.93     -0.07            602    1432.44         2.30   \n",
       "3      1.10       0.96      0.20            524     891.36         2.18   \n",
       "4      2.08       0.08     -0.10            496    1194.76         2.53   \n",
       "\n",
       "   Area_120  Round_120  Bright_120  Compact_120  ShpIndx_120  Mean_G_120  \\\n",
       "0      7618       2.43      189.73         3.62         3.40      163.61   \n",
       "1      1377       0.46       49.82         1.07         1.32       38.88   \n",
       "2      2901       2.00       46.57         2.78         2.79       40.01   \n",
       "3      1660       1.65       69.80         2.20         3.22       86.22   \n",
       "4      2351       1.05       96.24         2.00         2.56       82.84   \n",
       "\n",
       "   Mean_R_120  Mean_NIR_120  SD_G_120  SD_R_120  SD_NIR_120  LW_120  \\\n",
       "0      201.29        204.28     25.25     28.33       28.30    3.82   \n",
       "1       51.21         59.38     10.07     11.89       12.01    3.70   \n",
       "2       46.34         53.36     14.49     11.78       12.31    3.57   \n",
       "3       58.03         65.15     47.93     26.70       27.67    6.33   \n",
       "4      100.31        105.55     30.51     32.60       32.05    1.01   \n",
       "\n",
       "   GLCM1_120  Rect_120  GLCM2_120  Dens_120  Assym_120  NDVI_120  \\\n",
       "0       0.79      0.57       8.35      0.96       0.96     -0.10   \n",
       "1       0.52      0.96       7.01      1.69       0.86     -0.14   \n",
       "2       0.65      0.60       7.11      1.16       0.93     -0.07   \n",
       "3       0.89      0.70       8.56      1.10       0.96      0.20   \n",
       "4       0.83      0.75       8.62      2.08       0.08     -0.10   \n",
       "\n",
       "   BordLngth_120  GLCM3_120  BrdIndx_140  Area_140  Round_140  Bright_140  \\\n",
       "0           1188    1298.99         2.93      9172       2.50      185.14   \n",
       "1            196    2659.74         1.07      1377       0.46       49.82   \n",
       "2            602    1432.44         3.33      5932       1.69       55.06   \n",
       "3            524     891.36         2.18      1660       1.65       69.80   \n",
       "4            496    1194.76         2.53      2351       1.05       96.24   \n",
       "\n",
       "   Compact_140  ShpIndx_140  Mean_G_140  Mean_R_140  Mean_NIR_140  SD_G_140  \\\n",
       "0         3.94         3.95      159.45      196.43        199.53     27.81   \n",
       "1         1.07         1.32       38.88       51.21         59.38     10.07   \n",
       "2         2.68         3.89       59.76       48.66         56.76     30.65   \n",
       "3         2.20         3.22       86.22       58.03         65.15     47.93   \n",
       "4         2.00         2.56       82.84      100.31        105.55     30.51   \n",
       "\n",
       "   SD_R_140  SD_NIR_140  LW_140  GLCM1_140  Rect_140  GLCM2_140  Dens_140  \\\n",
       "0     31.55       31.15    5.04       0.80      0.58       8.56      0.82   \n",
       "1     11.89       12.01    3.70       0.52      0.96       7.01      1.69   \n",
       "2     18.59       18.75    3.09       0.90      0.63       8.32      1.38   \n",
       "3     26.70       27.67    6.33       0.89      0.70       8.56      1.10   \n",
       "4     32.60       32.05    1.01       0.83      0.75       8.62      2.08   \n",
       "\n",
       "   Assym_140  NDVI_140  BordLngth_140  GLCM3_140  \n",
       "0       0.98     -0.10           1512    1287.52  \n",
       "1       0.86     -0.14            196    2659.74  \n",
       "2       0.84      0.10           1198     720.38  \n",
       "3       0.96      0.20            524     891.36  \n",
       "4       0.08     -0.10            496    1194.76  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum ranges = BrdIndx = 3.5300000000000002\n",
      "Range of column Area = 5745\n",
      "Minimum ranges = Round = 3.52\n",
      "Range of column Bright = 5745\n",
      "Range of column Compact = 5745\n",
      "Range of column ShpIndx = 5745\n",
      "Range of column Mean_G = 5745\n",
      "Range of column Mean_R = 5745\n",
      "Range of column Mean_NIR = 5745\n",
      "Range of column SD_G = 5745\n",
      "Range of column SD_R = 5745\n",
      "Range of column SD_NIR = 5745\n",
      "Range of column LW = 5745\n",
      "Minimum ranges = GLCM1 = 0.8\n",
      "Minimum ranges = Rect = 0.76\n",
      "Range of column GLCM2 = 5745\n",
      "Range of column Dens = 5745\n",
      "Range of column Assym = 5745\n",
      "Range of column NDVI = 5745\n",
      "Range of column BordLngth = 5745\n",
      "Range of column GLCM3 = 5745\n",
      "Range of column BrdIndx_40 = 5745\n",
      "Range of column Area_40 = 5745\n",
      "Range of column Round_40 = 5745\n",
      "Range of column Bright_40 = 5745\n",
      "Range of column Compact_40 = 5745\n",
      "Range of column ShpIndx_40 = 5745\n",
      "Range of column Mean_G_40 = 5745\n",
      "Range of column Mean_R_40 = 5745\n",
      "Range of column Mean_NIR_40 = 5745\n",
      "Range of column SD_G_40 = 5745\n",
      "Range of column SD_R_40 = 5745\n",
      "Range of column SD_NIR_40 = 5745\n",
      "Range of column LW_40 = 5745\n",
      "Range of column GLCM1_40 = 5745\n",
      "Range of column Rect_40 = 5745\n",
      "Range of column GLCM2_40 = 5745\n",
      "Range of column Dens_40 = 5745\n",
      "Range of column Assym_40 = 5745\n",
      "Range of column NDVI_40 = 5745\n",
      "Range of column BordLngth_40 = 5745\n",
      "Range of column GLCM3_40 = 5745\n",
      "Range of column BrdIndx_60 = 5745\n",
      "Range of column Area_60 = 5745\n",
      "Range of column Round_60 = 5745\n",
      "Range of column Bright_60 = 5745\n",
      "Range of column Compact_60 = 5745\n",
      "Range of column ShpIndx_60 = 5745\n",
      "Range of column Mean_G_60 = 5745\n",
      "Range of column Mean_R_60 = 5745\n",
      "Range of column Mean_NIR_60 = 5745\n",
      "Range of column SD_G_60 = 5745\n",
      "Range of column SD_R_60 = 5745\n",
      "Range of column SD_NIR_60 = 5745\n",
      "Range of column LW_60 = 5745\n",
      "Range of column GLCM1_60 = 5745\n",
      "Range of column Rect_60 = 5745\n",
      "Range of column GLCM2_60 = 5745\n",
      "Range of column Dens_60 = 5745\n",
      "Range of column Assym_60 = 5745\n",
      "Minimum ranges = NDVI_60 = 0.74\n",
      "Range of column BordLngth_60 = 5745\n",
      "Range of column GLCM3_60 = 5745\n",
      "Range of column BrdIndx_80 = 5745\n",
      "Range of column Area_80 = 5745\n",
      "Range of column Round_80 = 5745\n",
      "Range of column Bright_80 = 5745\n",
      "Range of column Compact_80 = 5745\n",
      "Range of column ShpIndx_80 = 5745\n",
      "Range of column Mean_G_80 = 5745\n",
      "Range of column Mean_R_80 = 5745\n",
      "Range of column Mean_NIR_80 = 5745\n",
      "Range of column SD_G_80 = 5745\n",
      "Range of column SD_R_80 = 5745\n",
      "Range of column SD_NIR_80 = 5745\n",
      "Range of column LW_80 = 5745\n",
      "Range of column GLCM1_80 = 5745\n",
      "Range of column Rect_80 = 5745\n",
      "Range of column GLCM2_80 = 5745\n",
      "Range of column Dens_80 = 5745\n",
      "Range of column Assym_80 = 5745\n",
      "Range of column NDVI_80 = 5745\n",
      "Range of column BordLngth_80 = 5745\n",
      "Range of column GLCM3_80 = 5745\n",
      "Range of column BrdIndx_100 = 5745\n",
      "Range of column Area_100 = 5745\n",
      "Range of column Round_100 = 5745\n",
      "Range of column Bright_100 = 5745\n",
      "Range of column Compact_100 = 5745\n",
      "Range of column ShpIndx_100 = 5745\n",
      "Range of column Mean_G_100 = 5745\n",
      "Range of column Mean_R_100 = 5745\n",
      "Range of column Mean_NIR_100 = 5745\n",
      "Range of column SD_G_100 = 5745\n",
      "Range of column SD_R_100 = 5745\n",
      "Range of column SD_NIR_100 = 5745\n",
      "Range of column LW_100 = 5745\n",
      "Range of column GLCM1_100 = 5745\n",
      "Range of column Rect_100 = 5745\n",
      "Range of column GLCM2_100 = 5745\n",
      "Range of column Dens_100 = 5745\n",
      "Range of column Assym_100 = 5745\n",
      "Range of column NDVI_100 = 5745\n",
      "Range of column BordLngth_100 = 5745\n",
      "Range of column GLCM3_100 = 5745\n",
      "Range of column BrdIndx_120 = 5745\n",
      "Range of column Area_120 = 5745\n",
      "Range of column Round_120 = 5745\n",
      "Range of column Bright_120 = 5745\n",
      "Range of column Compact_120 = 5745\n",
      "Range of column ShpIndx_120 = 5745\n",
      "Range of column Mean_G_120 = 5745\n",
      "Range of column Mean_R_120 = 5745\n",
      "Range of column Mean_NIR_120 = 5745\n",
      "Range of column SD_G_120 = 5745\n",
      "Range of column SD_R_120 = 5745\n",
      "Range of column SD_NIR_120 = 5745\n",
      "Range of column LW_120 = 5745\n",
      "Range of column GLCM1_120 = 5745\n",
      "Range of column Rect_120 = 5745\n",
      "Range of column GLCM2_120 = 5745\n",
      "Range of column Dens_120 = 5745\n",
      "Range of column Assym_120 = 5745\n",
      "Minimum ranges = NDVI_120 = 0.73\n",
      "Range of column BordLngth_120 = 5745\n",
      "Range of column GLCM3_120 = 5745\n",
      "Range of column BrdIndx_140 = 5745\n",
      "Range of column Area_140 = 5745\n",
      "Range of column Round_140 = 5745\n",
      "Range of column Bright_140 = 5745\n",
      "Range of column Compact_140 = 5745\n",
      "Range of column ShpIndx_140 = 5745\n",
      "Range of column Mean_G_140 = 5745\n",
      "Range of column Mean_R_140 = 5745\n",
      "Range of column Mean_NIR_140 = 5745\n",
      "Range of column SD_G_140 = 5745\n",
      "Range of column SD_R_140 = 5745\n",
      "Range of column SD_NIR_140 = 5745\n",
      "Range of column LW_140 = 5745\n",
      "Range of column GLCM1_140 = 5745\n",
      "Range of column Rect_140 = 5745\n",
      "Range of column GLCM2_140 = 5745\n",
      "Range of column Dens_140 = 5745\n",
      "Range of column Assym_140 = 5745\n",
      "Range of column NDVI_140 = 5745\n",
      "Range of column BordLngth_140 = 5745\n",
      "Range of column GLCM3_140 = 5745\n"
     ]
    }
   ],
   "source": [
    "pd.reset_option('display.max_columns')\n",
    "r_min = X_train.iloc[:, 1].max() - X_train.iloc[:, 1].min()\n",
    "r_max = r_min\n",
    "for x in X_train.columns:\n",
    "    r = X_train[x].max() - X_train[x].min()\n",
    "    if r < r_min:\n",
    "        r_min = r\n",
    "        print(\"Minimum ranges = \" + x + \" = \" + str(r_min))\n",
    "    elif (r >= r_max) | (r != 5745):\n",
    "        r = r_max\n",
    "        print(\"Range of column \" + x + \" = \" + str(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Describe conceptually what the purpose of a kernel is for Support Vector Machines.<br>\n",
    "Kernels are used in Support Vector Machines (SVMs) to solve regression and classification problems. Support Vector Machines use the Kernel Trick to transform linearly inseparable data into linearly separable data, thus finding an optimal boundary for possible outputs. The Kernel function will usually convert the training set of data so that a non-linear decision surface can be transformed to a linear equation in a higher number of dimension spaces.\n",
    "Support vector machines use various kinds of kernel methods:\n",
    "- Linear\n",
    "- Polynomial\n",
    "- Radial Basis Function (RBF)\n",
    "- Sigmoid\n",
    "- Gaussian"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
